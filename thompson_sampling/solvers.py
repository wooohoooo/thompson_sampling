# AUTOGENERATED! DO NOT EDIT! File to edit: 04_solvers.ipynb (unless otherwise specified).

__all__ = ['AB', 'BetaBandit', 'LogisticThompsonSampler']

# Cell
from .abstractions import AbstractSolver, AbstractContextualSolver
import numpy as np
import scipy.stats as stats
import matplotlib.cm as cm
import matplotlib.pyplot as plt


# Cell
class AB(AbstractSolver):
  def __init__(self, n_experiments=1000, num_options=2):
    self.trials = np.zeros(shape=(num_options,))
    self.successes = np.zeros(shape=(num_options,))
    self.experiments_done = 0
    self.n_experiments = n_experiments



  def choose_arm(self):
    """we choose to either randomly sample an arm
    or play the previously determined best choice"""

    # if we need more experimentation, we explore
    if self.experiments_done < self.n_experiments:
      arm = self.explore()
    # otherwise, we exploit
    else:
      arm = self.exploit()
    return arm


  def update(self, arm, reward):
    """Updates the arms about being played and about receiving a reward"""

    # simply count the number of trials and successes for each arm
    self.trials[arm] += 1
    if reward:
      self.successes[arm] += 1
    self.experiments_done += 1


  def explore(self):
    """returns arm 0 or arm 1 depending on a draw from interval [0,1]
    NOTE: this isn't necessarilyhow you'd do it in real life,
    please consult the sources for that case"""

    # literally choose by random which arm to return
    if np.random.random() <.5:
        return 0
    else:
        return 1

  def exploit(self):
    """returns arm with highest expected payoff
    Always the same arm after exploration phase"""

    # return the arm with the highest success rate
    return np.argmax(self.successes/self.trials)



# Cell
class BetaBandit(AbstractSolver):

    def __init__(self, num_options = 2, prior = None):
        """initialize BetaBandit"""
        self.num_options = num_options

        #setting the prior, either uninformative or user generated
        if prior == None:
            self.prior = np.ones(shape=(num_options,2))
        else:
            assert prior.shape == (num_options,2), f"the prior seems to have wrong dimensionality, please conform to (num_options, 2){(num_options,2)}"
            self.prior = prior

        self.trials = np.zeros(shape=(num_options,))
        self.successes = np.zeros(shape=(num_options,))


    def choose_arm(self):
        """draw from arms.
        arm with the highest expected outcome wins.
        expected outcome is determined stochastically, so even an arm with bad
        outcome until now will have a chance of being drawn"""

        sampled_theta=[]
        for i in range(self.num_options):

            dist = stats.beta(self.prior[i,0]+self.successes[i],
                              self.prior[i,1]+self.trials[i] - self.successes[i])

            sampled_theta += [dist.rvs()]

        return(sampled_theta.index(max(sampled_theta)))

    def update(self,arm,success):
        """update beta-parameters of specific arm"""
        #count times arm has been drawn"""
        self.trials[arm] = self.trials[arm] +1
        #count number of successes on that arm"""

        # for decay factors: self.successes = self.successes *.99
        if success:
            self.successes[arm] = self.successes[arm]+ 1






# helpers

    def choose_arm_and_plot(self):


        sampled_theta = []
        dist_heights = []


        for i in range(self.num_options):

            dist = stats.beta(self.prior[i,0]+self.successes[i],
                              self.prior[i,1]+self.trials[i] - self.successes[i])
            sample = dist.rvs()
            sampled_theta += [sample]
            dist_heights += [dist.pdf(sample)]


        w = 10
        z = 5
        colors = iter(cm.rainbow(np.linspace(0, 1, self.num_options)))

        for k,i in enumerate(range(self.num_options)):
                color = next(colors)

                dist = stats.beta(self.prior[i,0] + self.successes[i],
                            self.prior[i,1] + self.trials[i] - self.successes[i])
                x = np.linspace(0,1,100)
                y = dist.pdf(x)
                plt.plot(x,y,color=color,label="arm #%i"%(i+1),alpha=0.8)

                plt.scatter(sampled_theta[i],dist_heights[i], s = 200,label=f'sample drawn from arm {i}')

                plt.fill_between(x,0,y,alpha=1/(self.num_options+1),color=color)
                leg = plt.legend()
                plt.tight_layout

        return(sampled_theta.index(max(sampled_theta)))


    def plot_params(self):
        """plot the distributions that underly the arms"""

        w = 10
        z = 5
        colors = iter(cm.rainbow(np.linspace(0, 1, self.num_options)))

        for k,i in enumerate(range(self.num_options)):
                color = next(colors)

                dist = stats.beta(self.prior[i,0] + self.successes[i],
                            self.prior[i,1] + self.trials[i] - self.successes[i])
                x = np.linspace(0,1,100)
                y = dist.pdf(x)
                plt.plot(x,y,color=color,label="arm #%i"%(i+1))
                plt.fill_between(x,0,y,alpha=1/self.num_options,color=color)
                leg = plt.legend()
                plt.tight_layout


# Cell
class LogisticThompsonSampler(AbstractContextualSolver):


    def update(self,arm,context,reward):

        model = self.model_list[arm]
        #X =  np.atleast_1d(np.append(arm, context))
        X = np.atleast_2d(context)
        # print(f'X {X}')

        reward = np.atleast_1d(reward)
        #model.observe(X.reshape(1,-1), reward.reshape(1,-1))
        model.observe(X, reward)

    def choose_arm(self,context):
        reward_list = []

        for arm in range(self.num_arms):
            model = self.model_list[arm]
            X = np.atleast_2d(context)

            probas = model.predict_proba(X)

            reward_sample = probas[0][1]

            # print(reward_sample)

            reward_list += [reward_sample]



        return np.argmax(reward_list)







# helpers

    def plot_params(self):
        colors = iter(cm.rainbow(np.linspace(0, 1, self.num_arms)))

        for arm in range(len(self.model_list)):
            color = next(colors)

            model = self.model_list[arm]
            X_pdf = np.linspace(-2, 2, 1000)
            pdf = stats.norm(loc=model.m, scale=model.q**(-1.0)).pdf(X_pdf)


            # plotting distriution of weights
            plt.plot(X_pdf, pdf, color=color, linewidth=2, alpha=0.5, label=f'estimated parameter arm {arm}')
            plt.fill_between(X_pdf, pdf, 0, color=color, alpha=0.2)
            plt.legend()



    def choose_arm_and_plot(self,context):
        colors = iter(cm.rainbow(np.linspace(0, 1, self.num_arms)))
        reward_list = []


        for arm in range(self.num_arms):
            model = self.model_list[arm]
            X = np.atleast_1d(context)


            reward_sample = model.predict_proba(X)[0]
            reward_list += [reward_sample]

            # plot
            color = next(colors)

            model = self.model_list[arm]
            X_pdf = np.linspace(-2, 2, 1000)
            dist = stats.norm(loc=model.m, scale=model.alpha**(-1.0))
            pdf = dist.pdf(X_pdf)

            height = dist.pdf(reward_sample)


            # plotting distriution of weights
            plt.plot(X_pdf, pdf, color=color, linewidth=2, alpha=0.5, label=f'estimated parameter arm {arm}')
            plt.fill_between(X_pdf, pdf, 0, color=color, alpha=0.2)


            plt.scatter(reward_sample, height, s = 200,label=f'sample drawn from arm {arm}')

            plt.legend()
        return np.argmax(reward_list)
